apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: torch-resnet-pipeline
  labels:
    inference_framework: kserve
    ML_framework: torch
spec:
  predictor:
    containers:
      - name: kserve-resnet-predictor-container
        image: kserve-torch-resnet-predictor:v1
        ports:
          - containerPort: 8080
        args:
          - --model_name
          - kserve_resnet
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "512Mi"
            cpu: "500m"
  transformer:
    containers:
      - image: kserve-torch-resnet-transformer:v1
        name: kserve-resnet-transformer-container
        ports:
          - containerPort: 8080
        args:
          - --model_name
          - kserve_resnet
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "512Mi"
            cpu: "500m"
